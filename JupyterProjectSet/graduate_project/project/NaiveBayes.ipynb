{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7756691",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#朴素贝叶斯\" data-toc-modified-id=\"朴素贝叶斯-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>朴素贝叶斯</a></span><ul class=\"toc-item\"><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>数据预处理</a></span><ul class=\"toc-item\"><li><span><a href=\"#做一些处理-去重-去除停用词-合并同义词-去除空白值-去除停用词也可以在分词这一步做\" data-toc-modified-id=\"做一些处理-去重-去除停用词-合并同义词-去除空白值-去除停用词也可以在分词这一步做-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>做一些处理 去重 去除停用词 合并同义词 去除空白值 去除停用词也可以在分词这一步做</a></span></li></ul></li><li><span><a href=\"#jieba分词\" data-toc-modified-id=\"jieba分词-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>jieba分词</a></span></li></ul></li><li><span><a href=\"#提取特征\" data-toc-modified-id=\"提取特征-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>提取特征</a></span></li><li><span><a href=\"#划分数据集\" data-toc-modified-id=\"划分数据集-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>划分数据集</a></span></li><li><span><a href=\"#训练模型\" data-toc-modified-id=\"训练模型-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>训练模型</a></span></li><li><span><a href=\"#训练模型\" data-toc-modified-id=\"训练模型-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>训练模型</a></span></li><li><span><a href=\"#测试模型\" data-toc-modified-id=\"测试模型-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>测试模型</a></span></li><li><span><a href=\"#保存-分析数据\" data-toc-modified-id=\"保存-分析数据-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>保存 分析数据</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f292a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标注数据 一定要统一标准 LDE tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5f04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378f5dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>陈姥姥和何老师讲的特别棒，收获颇丰</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>很好很贴心！</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>有点敷衍了，内容少，连贯性一般，差强人意</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>视频讲解非常详细</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>没给代码，课件也没有</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Comment  Sentiment\n",
       "0     陈姥姥和何老师讲的特别棒，收获颇丰          1\n",
       "1                很好很贴心！          1\n",
       "2  有点敷衍了，内容少，连贯性一般，差强人意          0\n",
       "3              视频讲解非常详细          1\n",
       "4            没给代码，课件也没有          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r\"../data/TrainData.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310cb3c",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b74ae",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01eecf",
   "metadata": {},
   "source": [
    "##### 做一些处理 去重 去除停用词 合并同义词 去除空白值 去除停用词也可以在分词这一步做"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6785d82",
   "metadata": {},
   "source": [
    "#### jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77b23f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\20866\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.542 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "import re\n",
    "\n",
    "dict_file = r\"../stop_dic/user_dict.txt\"\n",
    "stop_file = r\"../stop_dic/hit_stopwords.txt\"\n",
    "\n",
    "def chinese_word_cut(my_text):\n",
    "    jieba.load_userdict(dict_file)\n",
    "    jieba.initialize()\n",
    "    \n",
    "    data_cut = jieba.lcut(my_text, cut_all=False)\n",
    "    # 创建一个stop_word列表，读取停用词文档，将停用词添加到列表中\n",
    "    stop_words_list = []\n",
    "    with open(r'../stop_dic/hit_stopwords.txt', 'r', encoding='utf-8') as fp:\n",
    "        for line in fp:\n",
    "            if len(line) > 0:\n",
    "                stop_words_list.append(line.strip())  # 将字符串前后的空格去掉\n",
    "                \n",
    "    # .新建一个列表，用于存放将分析文档库与停用词库对比后去除停用词的字符串\n",
    "    data_result = []\n",
    "    for i in data_cut:\n",
    "        if i not in stop_words_list:\n",
    "            i = i.replace(' ', '')\n",
    "            i = i.replace('\\n', '')\n",
    "            if i != '':\n",
    "                data_result.append(i)\n",
    "    text = ' '.join(data_result).replace('\\n', ' ')\n",
    "#     return \" \".join(jieba.cut(my_text))\n",
    "    return text\n",
    "data['cut_comment'] = data.Comment.apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a52dd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cut_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>陈姥姥和何老师讲的特别棒，收获颇丰</td>\n",
       "      <td>1</td>\n",
       "      <td>陈 姥姥 老师 讲 特别 棒 收获 颇丰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>很好很贴心！</td>\n",
       "      <td>1</td>\n",
       "      <td>很 好 很 贴心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>有点敷衍了，内容少，连贯性一般，差强人意</td>\n",
       "      <td>0</td>\n",
       "      <td>有点 敷衍 内容 少 连贯性 差强人意</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>视频讲解非常详细</td>\n",
       "      <td>1</td>\n",
       "      <td>视频 讲解 非常 详细</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>没给代码，课件也没有</td>\n",
       "      <td>0</td>\n",
       "      <td>没 代码 课件 没有</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Comment  Sentiment           cut_comment\n",
       "0     陈姥姥和何老师讲的特别棒，收获颇丰          1  陈 姥姥 老师 讲 特别 棒 收获 颇丰\n",
       "1                很好很贴心！          1              很 好 很 贴心\n",
       "2  有点敷衍了，内容少，连贯性一般，差强人意          0   有点 敷衍 内容 少 连贯性 差强人意\n",
       "3              视频讲解非常详细          1           视频 讲解 非常 详细\n",
       "4            没给代码，课件也没有          0            没 代码 课件 没有"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a608134",
   "metadata": {},
   "source": [
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9ee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # 单词别拼错了\n",
    "\n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file, encoding='utf-8') as fp:\n",
    "        stopwords = fp.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list\n",
    "stop_words_file = r\"../stop_dic/hit_stopwords.txt\"\n",
    "stopwords = get_custom_stopwords(stop_words_file)\n",
    "vect = CountVectorizer(max_df=0.8,  # max_df: 可用于删除过于频繁出现的术语\n",
    "                      min_df=5,  #  min_df: 用于删除不经常出现的术语。\n",
    "                      token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
    "                      stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d561201",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89474c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cut_comment']  # X表示评论的词语的一些特征 处理之前的特征\n",
    "y = data.Sentiment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25db82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a2f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de254e",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c1f365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareInstall\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>c语言</th>\n",
       "      <th>good</th>\n",
       "      <th>java</th>\n",
       "      <th>kmp</th>\n",
       "      <th>linux</th>\n",
       "      <th>mooc</th>\n",
       "      <th>nice</th>\n",
       "      <th>oj</th>\n",
       "      <th>ok</th>\n",
       "      <th>...</th>\n",
       "      <th>非常适合</th>\n",
       "      <th>预习</th>\n",
       "      <th>预期</th>\n",
       "      <th>颇丰</th>\n",
       "      <th>题目</th>\n",
       "      <th>风格</th>\n",
       "      <th>风趣</th>\n",
       "      <th>高效</th>\n",
       "      <th>魅力</th>\n",
       "      <th>鼓励</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  c语言  good  java  kmp  linux  mooc  nice  oj  ok  ...  非常适合  预习  预期  \\\n",
       "0    0    0     0     0    0      0     0     0   0   0  ...     0   0   0   \n",
       "1    0    0     0     0    0      0     0     0   0   0  ...     0   0   0   \n",
       "2    0    0     0     0    0      0     0     0   0   0  ...     0   0   0   \n",
       "3    0    0     0     0    0      0     0     0   0   0  ...     0   0   0   \n",
       "4    0    0     0     0    0      0     0     0   0   0  ...     0   0   0   \n",
       "\n",
       "   颇丰  题目  风格  风趣  高效  魅力  鼓励  \n",
       "0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 775 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names_out())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a69e10",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6e78fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279166666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "nb.fit(X_train_vect, y_train)\n",
    "\n",
    "train_score = nb.score(X_train_vect, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bcd787",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a850bf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9058333333333334\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(nb.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b88cb4",
   "metadata": {},
   "source": [
    "### 保存 分析数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ab2df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r\"../data/TestData.xlsx\")  # 里面的数据是完全没有标签的\n",
    "# data.head()  # 训练集  测试集 和 待分析的数据是不一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "884a655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment']\n",
    "X_vec = vect.transform(X)\n",
    "\n",
    "nb_result= nb.predict(X_vec)\n",
    "data['nb_result'] = nb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83a122c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>nb_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>老师授课很详细很具体很清楚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>没听明白和没理解的可以反复学习</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>课程内容十分充实，老师用心准备，详略得当张弛有度，一口气学一单元不觉得累，我觉得收获很大。华...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>零基础学习非常棒，详细的讲解，有效的练习</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>好好，教的好得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  nb_result\n",
       "0                                      老师授课很详细很具体很清楚          1\n",
       "1                                    没听明白和没理解的可以反复学习          1\n",
       "2  课程内容十分充实，老师用心准备，详略得当张弛有度，一口气学一单元不觉得累，我觉得收获很大。华...          1\n",
       "3                               零基础学习非常棒，详细的讲解，有效的练习          1\n",
       "4                                           好好，教的好得很          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa55599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data.to_excel(r\"../data/TestData.xlsx\", index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c07a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
